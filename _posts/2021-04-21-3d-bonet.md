---
author: "pgaleone"
layout: "post"
title:  "3D-BoNet analysis and TensorFlow 2 implementation"
slug:   "3D-BoNet analysis and TensorFlow 2 implementation"
date:    2021-09-28 8:00:00
categories: machine-learning
image: images/3dbonet/3d-bonet-architecture.png
tags: machine-learning
---

Instance segmentation on point clouds is a challenging problem. Point clouds are unordered, sparse, non-uniform, and finding non-regulars shapes is not trivial. Moreover, the number of points in a scene can easily surpass the million, making every algorithm on point clouds very computationally expensive.
The 3D-BoNet architecture [1] has been introduced recently to tackle the problem. This network is trainable end-to-end, and it mixes the results of a bounding box prediction branch with the output of an instance segmentation branch. The article contains a walkthrough of the paper, section by section, and at the end introduces the steps we followed to convert the original implementation (in TensorFlow 1) to our own implementation in TensorFlow 2.

<div class="blog-image-container">
    <figure>
        <img class="blog-image" alt="point mask prediction branch" src="/images/3dbonet/instance-header.png">
        <figcaption>A sample extracted from the paper [1]. On the left the input point cloud, center the instance segmentation result with 3D-BoNet, right the ground truth.</figcaption>
    </figure>
</div>

## Introduction

Instance segmentation is the natural intersection between object detection and semantic segmentation. Object detection tries to identify instances within the point cloud, while semantic segmentation assigns a semantic class to every point in the cloud.
Instance segmentation aims to classify every point like semantic segmentation, but now distinct objects from the same semantic class have different labels. For this reason, an instance segmentation model should be able to reason over multiple scales: it has to recognize fine details to classify the points correctly, and, at the same time, it has to take into account objects in their entirety.

Analysis of point clouds is burdensome because point clouds are inherently unordered, unstructured, and non-uniform. The approaches to work with point clouds can be divided into three families: projection-based, discretization-based, and point-based methods. In project-based methods, the point cloud is projected to a plane, and the resulting image is analyzed with image processing techniques. Discretization-based approaches organize points in a grid of voxels summarizing the point features in voxels. This discretization allows using 3D convolutional neural networks because it imposes a regular geometric structure. The main drawback of this representation is its memory footprint, which can be very high if the scene covers a large section of space.

The 3D-BoNet approach is point-based like SGPN [2], ASIS [3], JSIS3D [4], MASC [5], 3D-BEVIS [6], but all these methods do not explicitly detect object boundaries (the bounding boxes). Furthermore, they require computationally intensive post-processing, like mean-shift clustering.

Differently from previous models, 3D-BoNet directly regresses the vertices of instance bounding boxes. Then it selects the points belonging to the instance with a binary classifier applied to the points within the bounding box. For doing this, the authors introduced a **bounding box prediction module** and a series of carefully designed loss functions to directly learn object boolean masks.

The pure 3D-BoNet method does not require post-processing, but it only works on small point clouds (usually composed of 4096 points). It is necessary to split the cloud into spatial blocks to manage more numerous point clouds. A spatial block contains the points belonging to a vertical column of space with a basis measuring a 1-meter square. The number of points in a block is constant to allow the creation of batches. For this reason, from a single spatial block, many processing blocks are created by sampling points. 

## Architecture

<div class="blog-image-container">
    <figure>
        <img class="blog-image" alt="detailed architecture" src="/images/3dbonet/3d-bonet-architecture.png">
        <figcaption>The 3D-BoNet architecture</figcaption>
    </figure>
</div>

The architecture is very similar to a traditional architecture used on images: backbone (feature extractor) and different heads for multi-task learning.

The input point cloud $$\textbf{P} \in \mathbb{R}^{N \times k_0}$$ has $$N$$ points and $$ k_0 $$ feature channels (such as the location coordinates $$\{x,y,z\}$$ and color $$\{r,g,b\}$$). The backbone network extracts **point local features** $$\textbf{F}_l \in \mathbb{R}^{N \times k}$$, where $$k$$ is the length of feature vectors.
Then, local features are aggregated in a **global feature vector** $$\textbf{F}_g \in \mathbb{R}^{1 \times k}$$.

The **Bounding Box Prediction Branch** (BBPB) takes global features $$\textbf{F}_g$$ as input and regresses a **predefined and fixed set of bounding boxes** $$B$$ and the corresponding box scores $$B_s$$.

During the training, this branch is supervised with ground truth boxes. A **bounding box association layer** associates the most similar predicted bounding box to every ground truth box. The output of the association layer is a list of indices $$\textbf{A}$$ that describes the best pairing between boxes. Paired boxes are then compared with a multi-criteria loss.
The bounding box association layer and multi-criteria loss (the content of the yellow box in the figure) are discarded for inference.

In parallel with the BBPB, predicted boxes, local features $$\textbf{F}_l$$ and global features $$\textbf{F}_g$$ are fed into the **Point Mask Prediction Branch** (PMPB).

### Bounding Box Prediction Branch (BBPB)

<div class="blog-image-container">
    <figure>
        <img class="blog-image" alt="bbox prediction" src="/images/3dbonet/3d-bo-net-bbox.png">
    <figcaption> Bounding Box Predictiond Branch architecture </figcaption>
    </figure>
</div>

The goal of the BBPB is to predict a rectangular bounding box for each instance in a single forward pass without relying on predefined spatial anchors or RPN (Region Proposal Network). A bounding box is parametrized by a pair of opposed vertices: $$ \{ [x_\text{min}, y_\text{min}, z_\text{min}], [x_\text{max}, y_\text{max}, z_\text{max}]\} $$

As for all detection tasks, the number of total instances is variable.
The BBPB gets around this problem by predicting a **fixed number of bounding boxes together with confidence scores**.
At inference time, only the boxes with a high confidence score are retained.

Since the instances have no natural order, they are predicted in random order. For this reason, it is not trivial how to link predicted bounding boxes with ground truth labels to supervise the network. **Given a set of ground truth instances, we need to determine which predicted boxes best fit them.**
This problem can be formulated as an optimal assignment and solved using an existing solver.

To supervise the network during the training, the authors introduce a **bounding box association layer** that relies on the [Hungarian algorithm](https://en.wikipedia.org/wiki/Hungarian_algorithm) to perform the association. A multi-criteria loss pushes the network to minimize the distance between paired boxes. At the same time, the loss promotes the maximization of the coverage of instance points inside predicted boxes.

#### Bounding Box Association Layer

Given $$H$$ predicted bounding boxes $$\textbf{B} \in \mathbb{R}^{H \times 2 \times 3} $$ how can we use ground truth bounding boxes $$\bar{\textbf{B}} \in \mathbb{R}^{T \times 2 \times 3}$$ to supervise the network?

The Bounding Box Association Layer associates to every $$T$$ ground truth box one of the $$H$$ predicted boxes when $$T \leq H$$. When $$T > H$$, only the largest $$H$$ ground truth boxes are retained.

The associations between boxes can be encoded in a boolean **association matrix** $$A \in \mathbb{R}^{H \times T}$$ such that $$\textbf{A}_{i,j} = 1$$ if and only if the $$i^{\text{th}}$$ predicted bbox is assigned to the $$j^{\text{th}}$$ ground truth box.
At the same time the dissimilarity between any pair of boxes can be stored in the **cost matrix** $$\textbf{C} \in \mathbb{R}^{H \times T}$$
Hence, the box association problem is to find the optimal assignment matrix $$\textbf{A}$$ with the **minimal cost overall**:
$$ \mathbf{A} = \text{argmin}_{A} \sum_{i=1}^{H}{\sum_{j=1}^{T}{C_{i,j}A_{i,j}}} $$ subject to $$ \sum_{i=1}^{H}{A_{i,j}} = 1, \sum_{j=1}^{T}{A_{i,j}} \le 1, j \in {1,\ldots,T}, i \in {1,\ldots, H} $$
The problem above is an instance of the **linear assignment problem**, thus it can be solved with the **Hungarian algorithm**.

To evaluate the dissimilarity between the $$i^\text{th}$$ predicted bounding box and the $$j^\text{th}$$ ground truth box, the Euclidean distance between corresponding vertices is not enough, because nearby bounding boxes cover a very different amount of points associated to an instance. Therefore, also the **coverage** of instance points should be included the calculate the cost matrix $$\textbf{C}$$. The final association cost is the sum of 3 costs.

1. **Euclidean Distance between bounding boxes**. 
    A bounding box $$B_i$$ is represented by the coordinates of a pair of opposed vertices, so $$B_i \in \mathbb{R}^6$$ and we can define a distance between bounding boxes using the Euclidean distance in $$\mathbb{R}^6$$:

    $$C^{ed}_{i,j} = \frac{1}{6}\sum{(B_i - \overline{B}_j)^2}.$$

2. **Soft IoU on Points**. For every point of the point cloud, we can establish if it falls inside a bounding box or not.
    Thus, for a ground truth bounding box, we can compute a **hard-binary vector** $$\overline{q}\in \{0, 1\}^N$$ that for every point associates the value 1 if the point is inside the box or the value 0 if it is outside. 
    
    Since the cost has to be a differentiable function of the predicted bounding boxes, we have to define a differentiable version of $$\overline{q}$$ (named $$q$$) for predicted boxes.
    The vector $$q \in [0, 1]^N$$ is called **point-in-pred-box-probability** and its $$n^\text{th}$$ element is a function of the distance of the $$n^\text{th}$$ point from the vertices of the bounding box such that the deeper the point is inside of the box, the higher the value.

3. **Cross-Entropy Score**. The cross-entropy score between $$q_i$$ and $$\overline{q}_j$$ counterbalances the sIoU. As a matter of fact, the sIoU cost favours tighter boxes, while the cross-entropy prefers larger and more inclusive boxes. It's formally defined as:

    $$ C^\text{ces}_{i,j} = - \frac{1}{N}\sum_{n=1}^N{[\bar{q}_j^n \log q_i^n + (1 - \bar{q}_j^n)\log(1-q_i^n)]} $$


The final association cost between the $$i^\text{th}$$ predicted bounding box and the $$j^\text{th}$$ ground truth box is defined as:

$$ C_{i,j} = C^{ed}_{i,j} + C^{\text{sIoU}}_{i,j} + C^{\text{ces}}_{i,j}.$$

The entries in the cost matrix $$\mathbf{C}$$ are filled according to this formula and the association matrix $$ \mathbf{A} $$ is computed through the Hungrian algorithm.

#### Loss Functions

The association matrix $$ \mathbf{A} $$ allows to reorder the predicted boxes to place them in the same position of the most similar ground truth box.
The re-ordered bounding boxes can then be compared with ground truth bounding boxes, obtaining a differentiable **loss function** to supervise the model.
The loss function is composed of two parts.

**Multi-criteria Loss for Box prediction**.  We reuse and minimize the association cost previously defined, i.e.

$$ \mathcal{l_\text{bbox}} = \frac{1}{T} \sum_{t=1}^{T}{C^{ed}_{t,t} + C^{\text{sIoU}}_{t,t} + C^{\text{ces}}_{t,t}}.$$

Here we only minimize the cost of $$T$$ paired boxes, while the remaining $$H-T$$ boxes are ignored.
In practice, $$ \mathcal{l_\text{bbox}} $$ corresponds to the minimal cost found by the Hungarian algorithm.

**Loss for Box Score Prediction**. The predicted box scores $B_s$ aim to indicate the validity of the corresponding predicted boxes. 
During training, after reordering the predicted bounding boxes, the target scores is 1 for the first $$T$$ box scores and 0 for the remaining $$H-T$$ scores.
We can thus use the cross entropy loss for this binary classification task:

$$ \mathcal{l_\text{bbs}} = -\frac{1}{H} \left[ \sum_{t=1}^{T}{B^t_s} + \sum_{t=T+1}^{H}{\log(1- B^t_s)} \right] $$

This loss rewards correctly predicted bounding boxes and implicitly penalizes the cases where multiple similar boxes are regressed for a single instance.
During inference, the accepted bounding boxes are the ones whose box score exceeds a given threshold, therefore box scores determine the number of instances in the point cloud. 

### Point Mask Prediction Branch

<div class="blog-image-container">
    <figure>
        <img class="blog-image" alt="point mask prediction branch" src="/images/3dbonet/3d-pointmask-prediction.png">
        <figcaption>Point Mask Prediction Branch architecture</figcaption>
    </figure>
</div>

Given the predicted boxes $$\mathbb{B}$$, the point features $$F_l$$ and the global features $$F_g$$, the Point Mask Prediction Branch processes each bounding separately with shared neural layers to establish which points inside the bounding box belong to the detected instance.

For the $$i^\text{th}$$ predicted bounding box $$B_i$$ the estimated vertices and score are fused with processed features $$\tilde{F}_l$$ through concatenation, producing a **box-aware features** $$\widehat{F}_l$$. These features are then fed through shared layers terminating with a sigmoid activation function, predicting a point level probability mask, denoted as $$M_i$$. The full branch architecture is detailed in the figure above.

The predicted instance masks $$M$$ are associated with the ground truth masks according to the association matrix $$\mathbb{A}$. Due to imbalance of instance and background points, the **focal loss** with default hyper-parameters is used instead of standard cross-entropy loss. As in the bounding box prediction branch, only the valid $$T$$ paired masks are used for the loss $$\mathcal{l_\text{pmask}}$$.

## End-to-End implementation & semantic segmentation loss

Backbone of choice: PointNet++.

For semantic segmentation, pointwise softmax cross-entropy loss function is used $$\mathcal{l_\text{sem}}$$. Given an input point cloud P, all the branches are linked and end-to-end trained using a single combined multi-task loss:

$$ \mathcal{l_\text{all}} = \mathcal{l_\text{sem}} + \mathcal{l_\text{bbox}} + \mathcal{l_\text{bbs}} + \mathcal{l_\text{pmask}} $$


Optimizer Adam. lr: 5e-4, divided by 2 every 20 epochs.

---

[1] [Learning Object Bounding Boxes for 3D Instance Segmentation on Point Clouds](https://arxiv.org/abs/1906.01140)
[2] [SGPN: Similarity Group Proposal Network for 3D Point Cloud Instance Segmentation](https://arxiv.org/abs/1711.08588)
[3] [Associatively Segmenting Instances and Semantics in Point Clouds](https://arxiv.org/abs/1902.09852)
[4] [JSIS3D: Joint Semantic-Instance Segmentation of 3D Point Clouds with Multi-Task Pointwise Networks and Multi-Value Conditional Random Fields](https://arxiv.org/abs/1904.00699) 
[5] [MASC: Multi-scale Affinity with Sparse Convolution for 3D Instance Segmentation](https://arxiv.org/abs/1902.04478)
[6] [3D-BEVIS: Birds-Eye-View Instance Segmentation](https://arxiv.org/abs/1904.02199)